{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1ru3kuuaCR1o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in data:\", list(data.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbb6u5pbJAM3",
        "outputId": "e4a37d31-b64e-485f-d373-fd81520d7318"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in data: ['full_scorecard', 'team1', 'team2', 'team1_score', 'team2_score', 'toss_winner', 'toss_choice', 'winner', 'margin', 'man_of_the_match', 'stadium', 'place']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/ipl_dataset_cleaned.csv'\n",
        "if os.path.exists(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(\"Data loaded. Shape:\", data.shape)\n",
        "    print(\"Columns:\", list(data.columns))\n",
        "else:\n",
        "    print(\"Error: File not found. Ensure 'ipl_dataset_cleaned.csv' is in /content/.\")\n",
        "    raise FileNotFoundError(\"Upload or generate the cleaned data first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9LFa70JLrv5",
        "outputId": "bf3f752a-cf13-4a77-980e-4518ed452491"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded. Shape: (958, 12)\n",
            "Columns: ['full_scorecard', 'team1', 'team2', 'team1_score', 'team2_score', 'toss_winner', 'toss_choice', 'winner', 'margin', 'man_of_the_match', 'stadium', 'place']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add derived columns for wins and scores\n",
        "data['team1_win'] = (data['winner'] == data['team1']).astype(int)\n",
        "data['team2_win'] = (data['winner'] == data['team2']).astype(int)\n",
        "\n",
        "# Sort for rolling calculations (using index as proxy for order)\n",
        "data = data.reset_index(drop=True)\n",
        "# 1. Rolling Averages (Team Form): Last 5 matches' wins and scores\n",
        "data['team1_rolling_wins'] = data.groupby('team1')['team1_win'].rolling(5, min_periods=1).mean().reset_index(0, drop=True)\n",
        "data['team1_rolling_score'] = data.groupby('team1')['team1_score'].rolling(5, min_periods=1).mean().reset_index(0, drop=True)\n",
        "data['team2_rolling_wins'] = data.groupby('team2')['team2_win'].rolling(5, min_periods=1).mean().reset_index(0, drop=True)\n",
        "data['team2_rolling_score'] = data.groupby('team2')['team2_score'].rolling(5, min_periods=1).mean().reset_index(0, drop=True)\n",
        "\n",
        "# 2. Venue Averages: Average wins and scores at stadium\n",
        "venue_wins = data.groupby('stadium')['team1_win'].mean().to_dict()\n",
        "venue_scores = data.groupby('stadium')['team1_score'].mean().to_dict()\n",
        "data['venue_win_avg'] = data['stadium'].map(venue_wins)\n",
        "data['venue_score_avg'] = data['stadium'].map(venue_scores)\n",
        "\n",
        "# 3. Opponent-Specific Stats (Team vs Team - TvT): Average wins against opponent\n",
        "tvt_wins = data.groupby(['team1', 'team2'])['team1_win'].mean().to_dict()\n",
        "data['tvt_win_avg'] = data.apply(lambda x: tvt_wins.get((x['team1'], x['team2']), 0), axis=1)\n",
        "\n",
        "# 4. Career Stats: Cumulative averages per team\n",
        "data['team1_career_wins'] = data.groupby('team1')['team1_win'].expanding().mean().reset_index(0, drop=True)\n",
        "data['team1_career_score'] = data.groupby('team1')['team1_score'].expanding().mean().reset_index(0, drop=True)\n",
        "data['team2_career_wins'] = data.groupby('team2')['team2_win'].expanding().mean().reset_index(0, drop=True)\n",
        "data['team2_career_score'] = data.groupby('team2')['team2_score'].expanding().mean().reset_index(0, drop=True)\n",
        "\n",
        "# Fill NaNs with 0\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "print(\"Features engineered. Shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41wkItUgLz01",
        "outputId": "5f7c6c56-6f36-4820-9f8a-9447bd2965d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features engineered. Shape: (958, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels: Next match scores and wins (shift by 1 for each team)\n",
        "data['label_team1_score_next'] = data.groupby('team1')['team1_score'].shift(-1)\n",
        "data['label_team2_score_next'] = data.groupby('team2')['team2_score'].shift(-1)\n",
        "data['label_team1_win_next'] = data.groupby('team1')['team1_win'].shift(-1)\n",
        "data['label_team2_win_next'] = data.groupby('team2')['team2_win'].shift(-1)\n",
        "# Drop rows with NaN labels (last match for each team)\n",
        "data.dropna(subset=['label_team1_score_next'], inplace=True)\n",
        "\n",
        "print(\"Labels created. Shape after dropping NaNs:\", data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SST6qKTBMLdZ",
        "outputId": "dabdec2b-cada-4aa7-c4cc-2947fde96012"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels created. Shape after dropping NaNs: (943, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # No 'season' for time-series, so use random split (80% train, 20% test)\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['winner'] if 'winner' in data.columns else None)\n",
        "\n",
        "print(\"Train shape:\", train_data.shape, \"Test shape:\", test_data.shape)\n",
        "\n",
        "# Features and labels\n",
        "features = ['team1_rolling_wins', 'team1_rolling_score', 'team2_rolling_wins', 'team2_rolling_score', 'venue_win_avg', 'venue_score_avg', 'tvt_win_avg', 'team1_career_wins', 'team1_career_score', 'team2_career_wins', 'team2_career_score']\n",
        "X_train = train_data[features]\n",
        "y_train_score = train_data['label_team1_score_next']\n",
        "y_train_win = train_data['label_team1_win_next']\n",
        "X_test = test_data[features]\n",
        "y_test_score = test_data['label_team1_score_next']\n",
        "y_test_win = test_data['label_team1_win_next']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eflFnFQKMNiH",
        "outputId": "02de91d5-7235-41c3-c161-686018640c20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (754, 29) Test shape: (189, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Preprocessing and Save (Fixed for Mixed Data Types)\n",
        "\n",
        "# Make explicit copies of train_data and test_data to ensure transformations apply correctly\n",
        "train_data_processed = train_data.copy()\n",
        "test_data_processed = test_data.copy()\n",
        "\n",
        "# Encode categorical columns in the main 'data' DataFrame (for saving later)\n",
        "# Note: train_data and test_data will retain original categorical values unless explicitly processed\n",
        "encoder = LabelEncoder()\n",
        "categorical_cols = ['team1', 'team2', 'toss_winner', 'toss_choice', 'winner', 'man_of_the_match', 'stadium', 'place', 'full_scorecard']\n",
        "for col in categorical_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = encoder.fit_transform(data[col].astype(str))  # Convert to strings and encode\n",
        "\n",
        "# Convert 'margin' column to numeric, extracting only the integer part for the main 'data' DataFrame\n",
        "data['margin'] = data['margin'].astype(str).str.extract(r'(\\d+)').astype(float).fillna(0)\n",
        "\n",
        "# Apply the same margin cleaning to the processed train_data and test_data copies\n",
        "train_data_processed['margin'] = train_data_processed['margin'].astype(str).str.extract(r'(\\d+)').astype(float).fillna(0)\n",
        "test_data_processed['margin'] = test_data_processed['margin'].astype(str).str.extract(r'(\\d+)').astype(float).fillna(0)\n",
        "\n",
        "# Define numerical features (for scaling; include engineered and original numericals)\n",
        "numerical_features = ['team1_rolling_wins', 'team1_rolling_score', 'team2_rolling_wins', 'team2_rolling_score', 'venue_win_avg', 'venue_score_avg', 'tvt_win_avg', 'team1_career_wins', 'team1_career_score', 'team2_career_wins', 'team2_career_score', 'team1_score', 'team2_score', 'margin']\n",
        "\n",
        "# Update X_train and X_test to use numerical features from the processed data\n",
        "X_train_num = train_data_processed[numerical_features]\n",
        "y_train_score = train_data_processed['label_team1_score_next']\n",
        "y_train_win = train_data_processed['label_team1_win_next']\n",
        "X_test_num = test_data_processed[numerical_features]\n",
        "y_test_score = test_data_processed['label_team1_score_next']\n",
        "y_test_win = test_data_processed['label_team1_win_next']\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_num)\n",
        "X_test_scaled = scaler.transform(X_test_num)\n",
        "\n",
        "# Save feature-engineered dataset\n",
        "data.to_csv('/content/dataset.csv', index=False)\n",
        "print(\"Feature-engineered dataset saved as 'dataset.csv'.\")\n",
        "\n",
        "# Save preprocessor pipeline\n",
        "joblib.dump({'scaler': scaler, 'encoder': encoder}, '/content/feature_pipeline.pkl')\n",
        "print(\"Preprocessor saved as 'feature_pipeline.pkl'.\")\n",
        "\n",
        "# Optional: Quick check\n",
        "print(\"Sample scaled features shape:\", X_train_scaled.shape)\n",
        "print(\"Sample scaled features:\", X_train_scaled[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gHYR9H4uNLIe",
        "outputId": "f9ee1762-7b46-4f7f-b072-6c0d9c384615"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature-engineered dataset saved as 'dataset.csv'.\n",
            "Preprocessor saved as 'feature_pipeline.pkl'.\n",
            "Sample scaled features shape: (754, 14)\n",
            "Sample scaled features: [[ 0.          1.13561035  0.         -0.15244438  0.          0.09906591\n",
            "   0.          0.          0.47448872  0.          0.11889257  0.293608\n",
            "   0.3687034  -0.31247129]\n",
            " [ 0.          0.20554507  0.          0.77356908  0.         -0.18333829\n",
            "   0.          0.         -0.73987822  0.         -0.02026064  0.72678795\n",
            "   1.34301075 -0.36014497]\n",
            " [ 0.          0.32512489  0.          1.20209659  0.          0.31978101\n",
            "   0.          0.          0.35301453  0.          1.32667181  0.7777503\n",
            "   1.25443736 -0.50316603]]\n"
          ]
        }
      ]
    }
  ]
}